{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78da0df8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'layers' from 'tensorflow.keras.layers' (/Users/shubhibhadauriya/anaconda3/lib/python3.10/site-packages/keras/api/_v2/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InceptionResNetV2\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, GlobalAveragePooling2D, Dropout, layers\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'layers' from 'tensorflow.keras.layers' (/Users/shubhibhadauriya/anaconda3/lib/python3.10/site-packages/keras/api/_v2/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError \n",
    "\n",
    "\n",
    "csv_folder_path = '/Users/shubhibhadauriya/Desktop/Diss Project/osfstorage-archive (1)'  \n",
    "image_base_path = '/Users/shubhibhadauriya/Desktop/osfstorage-archive'\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(csv_folder_path) if f.endswith('.csv')]\n",
    "\n",
    "all_filenames = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "def find_image_file(csv_filename, image_dir):\n",
    "    parts = csv_filename.split('/')\n",
    "    timestamp_id = parts[-1].split('-')[0]\n",
    "    corrected_timestamp_id = timestamp_id.replace(':', '/')\n",
    "    for root, dirs, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            if corrected_timestamp_id in file:\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_images(filenames, base_path):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        img_path = find_image_file(filename, base_path)\n",
    "        if img_path and os.path.exists(img_path):\n",
    "            images.append(img_path)\n",
    "        else:\n",
    "            print(f\"File not found for CSV entry: {filename}\")\n",
    "            images.append(None)  \n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    csv_file_path = os.path.join(csv_folder_path, csv_file)\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    data = data.dropna()\n",
    "\n",
    "    \n",
    "    image_width, image_height = 960, 960  \n",
    "    data['lx'] = data['lx'] / image_width\n",
    "    data['ly'] = data['ly'] / image_height\n",
    "    data['rx'] = data['rx'] / image_width\n",
    "    data['ry'] = data['ry'] / image_height\n",
    "\n",
    "    features = ['lx', 'ly', 'rx', 'ry']\n",
    "\n",
    "    \n",
    "    filenames = data['filename'].values\n",
    "    images = load_images(filenames, image_base_path)\n",
    "    labels = data[features].values\n",
    "\n",
    "    \n",
    "    valid_indices = [i for i, img in enumerate(images) if img is not None]\n",
    "    images = images[valid_indices]\n",
    "    labels = labels[valid_indices]\n",
    "\n",
    "    \n",
    "    all_filenames.extend(images)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "\n",
    "all_filenames = tf.convert_to_tensor(all_filenames, dtype=tf.string)\n",
    "all_labels = tf.convert_to_tensor(all_labels, dtype=tf.float32)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_filenames, all_labels))\n",
    "\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=len(all_filenames), seed=38)\n",
    "\n",
    "\n",
    "sampled_dataset = dataset.take(1000)\n",
    "\n",
    "\n",
    "train_size = int(0.6 * 1000)\n",
    "val_size = int(0.2 * 1000)\n",
    "test_size = 1000 - train_size - val_size\n",
    "\n",
    "train_dataset = sampled_dataset.take(train_size)\n",
    "val_test_dataset = sampled_dataset.skip(train_size)\n",
    "val_dataset = val_test_dataset.take(val_size)\n",
    "test_dataset = val_test_dataset.skip(val_size)\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(filename, label):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [299, 299])  \n",
    "    image = image / 255.0  \n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.cache().batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(299, 299, 3))  \n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.6)(x)  \n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)  \n",
    "x = Dropout(0.6)(x) \n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "predictions = Dense(4, activation='linear')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "def euclidean_distance(true_coords, pred_coords):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(true_coords - pred_coords), axis=-1))\n",
    "\n",
    "def calculate_relative_error(y_true, y_pred):\n",
    "    true_lx, true_ly, true_rx, true_ry = tf.split(y_true, 4, axis=-1)\n",
    "    pred_lx, pred_ly, pred_rx, pred_ry = tf.split(y_pred, 4, axis=-1)\n",
    "\n",
    "    d_left_eye = euclidean_distance(tf.concat([true_lx, true_ly], axis=-1), \n",
    "                                    tf.concat([pred_lx, pred_ly], axis=-1))\n",
    "    d_right_eye = euclidean_distance(tf.concat([true_rx, true_ry], axis=-1), \n",
    "                                     tf.concat([pred_rx, pred_ry], axis=-1))\n",
    "\n",
    "    w = euclidean_distance(tf.concat([true_lx, true_ly], axis=-1), \n",
    "                           tf.concat([true_rx, true_ry], axis=-1))\n",
    "\n",
    "    relative_error_left = d_left_eye / w\n",
    "    relative_error_right = d_right_eye / w\n",
    "    relative_error = tf.maximum(relative_error_left, relative_error_right)\n",
    "    \n",
    "    return relative_error\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)  \n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=['mae', MeanAbsolutePercentageError(name=\"mean_absolute_percentage_error\"), calculate_relative_error])\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)  \n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=100,  \n",
    "                    callbacks=[reduce_lr, checkpoint])\n",
    "\n",
    "\n",
    "model.load_weights('best_model.keras')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title(f'{model_name} Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['mae'], label='train_mae')\n",
    "    plt.plot(history.history['val_mae'], label='val_mae')\n",
    "    plt.title(f'{model_name} MAE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['mean_absolute_percentage_error'], label='train_mape')\n",
    "    plt.plot(history.history['val_mean_absolute_percentage_error'], label='val_mape')\n",
    "    plt.title(f'{model_name} MAPE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['calculate_relative_error'], label='train_relative_error')\n",
    "    plt.plot(history.history['val_calculate_relative_error'], label='val_relative_error')\n",
    "    plt.title(f'{model_name} Relative Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c868dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 540s 26s/step - loss: 3.3264 - mae: 0.4809 - mean_absolute_percentage_error: 3363.8630 - calculate_relative_error: 934861.0000 - val_loss: 2.7028 - val_mae: 0.3458 - val_mean_absolute_percentage_error: 857.8730 - val_calculate_relative_error: 166310.1406 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 306s 16s/step - loss: 2.3714 - mae: 0.2545 - mean_absolute_percentage_error: 2605.7131 - calculate_relative_error: 687967.5625 - val_loss: 2.1126 - val_mae: 0.3375 - val_mean_absolute_percentage_error: 909.2706 - val_calculate_relative_error: 232243.3125 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 290s 16s/step - loss: 1.8455 - mae: 0.2228 - mean_absolute_percentage_error: 2531.0789 - calculate_relative_error: 624178.1875 - val_loss: 1.6763 - val_mae: 0.3169 - val_mean_absolute_percentage_error: 1018.7793 - val_calculate_relative_error: 237244.8750 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 264s 14s/step - loss: 1.4703 - mae: 0.1987 - mean_absolute_percentage_error: 2733.4944 - calculate_relative_error: 652121.5625 - val_loss: 1.3718 - val_mae: 0.3273 - val_mean_absolute_percentage_error: 964.4545 - val_calculate_relative_error: 227235.5781 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 258s 14s/step - loss: 1.2007 - mae: 0.1921 - mean_absolute_percentage_error: 2845.2002 - calculate_relative_error: 689375.8125 - val_loss: 1.1315 - val_mae: 0.3164 - val_mean_absolute_percentage_error: 1026.2625 - val_calculate_relative_error: 261160.2344 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 256s 14s/step - loss: 0.9884 - mae: 0.1781 - mean_absolute_percentage_error: 2743.7476 - calculate_relative_error: 663169.1250 - val_loss: 0.9397 - val_mae: 0.2912 - val_mean_absolute_percentage_error: 1166.9912 - val_calculate_relative_error: 264429.4688 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 248s 13s/step - loss: 0.8261 - mae: 0.1742 - mean_absolute_percentage_error: 2704.0481 - calculate_relative_error: 683150.4375 - val_loss: 0.8118 - val_mae: 0.3143 - val_mean_absolute_percentage_error: 1036.0297 - val_calculate_relative_error: 239236.4219 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 239s 13s/step - loss: 0.6912 - mae: 0.1593 - mean_absolute_percentage_error: 2745.7695 - calculate_relative_error: 690619.5000 - val_loss: 0.6884 - val_mae: 0.2962 - val_mean_absolute_percentage_error: 1137.8990 - val_calculate_relative_error: 264398.0625 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 272s 15s/step - loss: 0.5865 - mae: 0.1601 - mean_absolute_percentage_error: 2871.4346 - calculate_relative_error: 679584.0625 - val_loss: 0.5788 - val_mae: 0.2782 - val_mean_absolute_percentage_error: 1241.6681 - val_calculate_relative_error: 287133.0000 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 254s 13s/step - loss: 0.4946 - mae: 0.1396 - mean_absolute_percentage_error: 2861.2756 - calculate_relative_error: 702652.8125 - val_loss: 0.5044 - val_mae: 0.2754 - val_mean_absolute_percentage_error: 1257.2365 - val_calculate_relative_error: 276590.0938 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 257s 14s/step - loss: 0.4227 - mae: 0.1367 - mean_absolute_percentage_error: 2709.8933 - calculate_relative_error: 659700.9375 - val_loss: 0.4286 - val_mae: 0.2555 - val_mean_absolute_percentage_error: 1371.5253 - val_calculate_relative_error: 313331.3125 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 345s 18s/step - loss: 0.3654 - mae: 0.1362 - mean_absolute_percentage_error: 2811.0486 - calculate_relative_error: 682128.2500 - val_loss: 0.3738 - val_mae: 0.2473 - val_mean_absolute_percentage_error: 1417.7866 - val_calculate_relative_error: 318220.1875 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 332s 17s/step - loss: 0.3192 - mae: 0.1385 - mean_absolute_percentage_error: 2922.8459 - calculate_relative_error: 716886.2500 - val_loss: 0.3274 - val_mae: 0.2441 - val_mean_absolute_percentage_error: 1436.2825 - val_calculate_relative_error: 320385.8750 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 280s 15s/step - loss: 0.2774 - mae: 0.1300 - mean_absolute_percentage_error: 3015.1211 - calculate_relative_error: 737689.3750 - val_loss: 0.2895 - val_mae: 0.2401 - val_mean_absolute_percentage_error: 1459.0782 - val_calculate_relative_error: 338099.1250 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 262s 14s/step - loss: 0.2414 - mae: 0.1265 - mean_absolute_percentage_error: 2858.0010 - calculate_relative_error: 704646.5000 - val_loss: 0.2529 - val_mae: 0.2261 - val_mean_absolute_percentage_error: 1537.4165 - val_calculate_relative_error: 337847.1562 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.2127 - mae: 0.1234 - mean_absolute_percentage_error: 2874.5532 - calculate_relative_error: 705132.1875 - val_loss: 0.2243 - val_mae: 0.2234 - val_mean_absolute_percentage_error: 1553.3322 - val_calculate_relative_error: 350415.5312 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 229s 12s/step - loss: 0.1896 - mae: 0.1218 - mean_absolute_percentage_error: 3022.7686 - calculate_relative_error: 737998.0000 - val_loss: 0.1932 - val_mae: 0.2034 - val_mean_absolute_percentage_error: 1667.2957 - val_calculate_relative_error: 381042.0938 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 225s 12s/step - loss: 0.1667 - mae: 0.1199 - mean_absolute_percentage_error: 2884.9829 - calculate_relative_error: 704218.9375 - val_loss: 0.1605 - val_mae: 0.1606 - val_mean_absolute_percentage_error: 1911.3417 - val_calculate_relative_error: 442961.3125 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 226s 12s/step - loss: 0.1492 - mae: 0.1168 - mean_absolute_percentage_error: 2951.9756 - calculate_relative_error: 716064.5625 - val_loss: 0.1442 - val_mae: 0.1595 - val_mean_absolute_percentage_error: 1917.5060 - val_calculate_relative_error: 445000.4062 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 260s 14s/step - loss: 0.1347 - mae: 0.1157 - mean_absolute_percentage_error: 2975.2422 - calculate_relative_error: 728605.8125 - val_loss: 0.1303 - val_mae: 0.1590 - val_mean_absolute_percentage_error: 1920.4653 - val_calculate_relative_error: 450419.0938 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 276s 15s/step - loss: 0.1207 - mae: 0.1124 - mean_absolute_percentage_error: 2960.3542 - calculate_relative_error: 718609.6250 - val_loss: 0.1134 - val_mae: 0.1352 - val_mean_absolute_percentage_error: 2059.8418 - val_calculate_relative_error: 482240.4375 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 240s 13s/step - loss: 0.1112 - mae: 0.1145 - mean_absolute_percentage_error: 3007.8699 - calculate_relative_error: 733314.6875 - val_loss: 0.1022 - val_mae: 0.1280 - val_mean_absolute_percentage_error: 2104.7722 - val_calculate_relative_error: 490785.8125 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 256s 14s/step - loss: 0.1007 - mae: 0.1100 - mean_absolute_percentage_error: 3001.6243 - calculate_relative_error: 734719.1250 - val_loss: 0.0917 - val_mae: 0.1190 - val_mean_absolute_percentage_error: 2162.7275 - val_calculate_relative_error: 499429.4688 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0915 - mae: 0.1076 - mean_absolute_percentage_error: 2992.8474 - calculate_relative_error: 726302.7500 - val_loss: 0.0841 - val_mae: 0.1193 - val_mean_absolute_percentage_error: 2160.8970 - val_calculate_relative_error: 500894.7500 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 231s 12s/step - loss: 0.0840 - mae: 0.1070 - mean_absolute_percentage_error: 2991.2991 - calculate_relative_error: 729173.0625 - val_loss: 0.0757 - val_mae: 0.1068 - val_mean_absolute_percentage_error: 2249.1877 - val_calculate_relative_error: 519394.0938 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 228s 12s/step - loss: 0.0779 - mae: 0.1076 - mean_absolute_percentage_error: 3008.9915 - calculate_relative_error: 729807.5000 - val_loss: 0.0691 - val_mae: 0.1008 - val_mean_absolute_percentage_error: 2292.8882 - val_calculate_relative_error: 531062.5000 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.0721 - mae: 0.1034 - mean_absolute_percentage_error: 3039.8940 - calculate_relative_error: 740473.5000 - val_loss: 0.0636 - val_mae: 0.0946 - val_mean_absolute_percentage_error: 2343.8330 - val_calculate_relative_error: 544095.6250 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.0673 - mae: 0.1039 - mean_absolute_percentage_error: 3031.6990 - calculate_relative_error: 738759.4375 - val_loss: 0.0598 - val_mae: 0.1037 - val_mean_absolute_percentage_error: 2269.0579 - val_calculate_relative_error: 526400.1875 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.0630 - mae: 0.1056 - mean_absolute_percentage_error: 3024.9810 - calculate_relative_error: 734805.2500 - val_loss: 0.0557 - val_mae: 0.1007 - val_mean_absolute_percentage_error: 2296.5071 - val_calculate_relative_error: 530486.6250 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 234s 12s/step - loss: 0.0594 - mae: 0.1049 - mean_absolute_percentage_error: 3024.9067 - calculate_relative_error: 736379.3125 - val_loss: 0.0523 - val_mae: 0.1008 - val_mean_absolute_percentage_error: 2293.3557 - val_calculate_relative_error: 531112.4375 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.0561 - mae: 0.1054 - mean_absolute_percentage_error: 3019.9509 - calculate_relative_error: 732734.5625 - val_loss: 0.0491 - val_mae: 0.0998 - val_mean_absolute_percentage_error: 2298.7490 - val_calculate_relative_error: 534297.2500 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 232s 12s/step - loss: 0.0532 - mae: 0.1022 - mean_absolute_percentage_error: 3044.5095 - calculate_relative_error: 742356.3125 - val_loss: 0.0463 - val_mae: 0.0983 - val_mean_absolute_percentage_error: 2317.5151 - val_calculate_relative_error: 533876.8125 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 249s 13s/step - loss: 0.0506 - mae: 0.1056 - mean_absolute_percentage_error: 3010.5637 - calculate_relative_error: 730093.1875 - val_loss: 0.0440 - val_mae: 0.0983 - val_mean_absolute_percentage_error: 2312.4915 - val_calculate_relative_error: 536124.1875 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 227s 12s/step - loss: 0.0483 - mae: 0.1036 - mean_absolute_percentage_error: 3023.3567 - calculate_relative_error: 736570.5000 - val_loss: 0.0419 - val_mae: 0.0984 - val_mean_absolute_percentage_error: 2312.7908 - val_calculate_relative_error: 535151.8750 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 224s 12s/step - loss: 0.0464 - mae: 0.1036 - mean_absolute_percentage_error: 3026.9739 - calculate_relative_error: 735339.2500 - val_loss: 0.0400 - val_mae: 0.0953 - val_mean_absolute_percentage_error: 2336.2937 - val_calculate_relative_error: 542083.9375 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0447 - mae: 0.1031 - mean_absolute_percentage_error: 3023.4346 - calculate_relative_error: 737169.2500 - val_loss: 0.0386 - val_mae: 0.0986 - val_mean_absolute_percentage_error: 2310.1924 - val_calculate_relative_error: 536065.3750 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 226s 12s/step - loss: 0.0433 - mae: 0.1051 - mean_absolute_percentage_error: 3010.9036 - calculate_relative_error: 733690.4375 - val_loss: 0.0371 - val_mae: 0.0969 - val_mean_absolute_percentage_error: 2323.0229 - val_calculate_relative_error: 538809.3750 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 222s 12s/step - loss: 0.0418 - mae: 0.1031 - mean_absolute_percentage_error: 3027.8782 - calculate_relative_error: 736511.1250 - val_loss: 0.0358 - val_mae: 0.0976 - val_mean_absolute_percentage_error: 2317.9529 - val_calculate_relative_error: 537360.2500 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 3694s 205s/step - loss: 0.0406 - mae: 0.1040 - mean_absolute_percentage_error: 3026.5713 - calculate_relative_error: 735154.1875 - val_loss: 0.0346 - val_mae: 0.0973 - val_mean_absolute_percentage_error: 2321.2500 - val_calculate_relative_error: 538197.8750 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 239s 13s/step - loss: 0.0394 - mae: 0.1037 - mean_absolute_percentage_error: 3014.6960 - calculate_relative_error: 734926.4375 - val_loss: 0.0336 - val_mae: 0.0962 - val_mean_absolute_percentage_error: 2327.9211 - val_calculate_relative_error: 540463.6250 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 221s 12s/step - loss: 0.0387 - mae: 0.1037 - mean_absolute_percentage_error: 3028.2600 - calculate_relative_error: 738517.2500 - val_loss: 0.0329 - val_mae: 0.0996 - val_mean_absolute_percentage_error: 2303.5522 - val_calculate_relative_error: 533353.7500 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 235s 12s/step - loss: 0.0378 - mae: 0.1058 - mean_absolute_percentage_error: 3004.4814 - calculate_relative_error: 730254.0000 - val_loss: 0.0318 - val_mae: 0.0951 - val_mean_absolute_percentage_error: 2340.0164 - val_calculate_relative_error: 542396.4375 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 227s 12s/step - loss: 0.0370 - mae: 0.1023 - mean_absolute_percentage_error: 3038.5659 - calculate_relative_error: 740159.5000 - val_loss: 0.0312 - val_mae: 0.0965 - val_mean_absolute_percentage_error: 2324.7480 - val_calculate_relative_error: 540328.3750 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 227s 12s/step - loss: 0.0363 - mae: 0.1045 - mean_absolute_percentage_error: 3009.9192 - calculate_relative_error: 732979.8125 - val_loss: 0.0305 - val_mae: 0.0968 - val_mean_absolute_percentage_error: 2324.2268 - val_calculate_relative_error: 538798.5000 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 222s 12s/step - loss: 0.0357 - mae: 0.1036 - mean_absolute_percentage_error: 3026.4099 - calculate_relative_error: 736517.7500 - val_loss: 0.0299 - val_mae: 0.0966 - val_mean_absolute_percentage_error: 2326.4585 - val_calculate_relative_error: 539575.6875 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 230s 12s/step - loss: 0.0351 - mae: 0.1033 - mean_absolute_percentage_error: 3026.9424 - calculate_relative_error: 737016.1875 - val_loss: 0.0294 - val_mae: 0.0964 - val_mean_absolute_percentage_error: 2326.4216 - val_calculate_relative_error: 540262.5000 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 223s 12s/step - loss: 0.0347 - mae: 0.1043 - mean_absolute_percentage_error: 3020.1943 - calculate_relative_error: 735743.5625 - val_loss: 0.0292 - val_mae: 0.0989 - val_mean_absolute_percentage_error: 2307.0889 - val_calculate_relative_error: 534922.2500 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 216s 12s/step - loss: 0.0343 - mae: 0.1038 - mean_absolute_percentage_error: 3027.6313 - calculate_relative_error: 736567.7500 - val_loss: 0.0285 - val_mae: 0.0946 - val_mean_absolute_percentage_error: 2344.4097 - val_calculate_relative_error: 543164.1875 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 223s 12s/step - loss: 0.0341 - mae: 0.1054 - mean_absolute_percentage_error: 3012.6274 - calculate_relative_error: 730978.2500 - val_loss: 0.0283 - val_mae: 0.0950 - val_mean_absolute_percentage_error: 2338.0630 - val_calculate_relative_error: 543458.7500 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 220s 12s/step - loss: 0.0336 - mae: 0.1029 - mean_absolute_percentage_error: 3029.5227 - calculate_relative_error: 738722.9375 - val_loss: 0.0279 - val_mae: 0.0955 - val_mean_absolute_percentage_error: 2333.9424 - val_calculate_relative_error: 542126.5000 - lr: 0.0010\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 231s 12s/step - loss: 0.0332 - mae: 0.1042 - mean_absolute_percentage_error: 3015.3115 - calculate_relative_error: 734416.0625 - val_loss: 0.0277 - val_mae: 0.0973 - val_mean_absolute_percentage_error: 2319.8054 - val_calculate_relative_error: 538418.3750 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 29032s 1612s/step - loss: 0.0329 - mae: 0.1034 - mean_absolute_percentage_error: 3031.8528 - calculate_relative_error: 737536.7500 - val_loss: 0.0272 - val_mae: 0.0943 - val_mean_absolute_percentage_error: 2343.3296 - val_calculate_relative_error: 544866.1250 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 33710s 17s/step - loss: 0.0326 - mae: 0.1032 - mean_absolute_percentage_error: 3029.0886 - calculate_relative_error: 737102.0000 - val_loss: 0.0271 - val_mae: 0.0976 - val_mean_absolute_percentage_error: 2319.7280 - val_calculate_relative_error: 537234.9375 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 303s 16s/step - loss: 0.0325 - mae: 0.1047 - mean_absolute_percentage_error: 3021.3770 - calculate_relative_error: 734899.6250 - val_loss: 0.0269 - val_mae: 0.0964 - val_mean_absolute_percentage_error: 2327.1460 - val_calculate_relative_error: 540706.5000 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 253s 14s/step - loss: 0.0322 - mae: 0.1038 - mean_absolute_percentage_error: 3022.6155 - calculate_relative_error: 735888.5625 - val_loss: 0.0266 - val_mae: 0.0956 - val_mean_absolute_percentage_error: 2333.6072 - val_calculate_relative_error: 541947.1250 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 275s 15s/step - loss: 0.0320 - mae: 0.1033 - mean_absolute_percentage_error: 3024.9182 - calculate_relative_error: 736706.9375 - val_loss: 0.0264 - val_mae: 0.0950 - val_mean_absolute_percentage_error: 2338.4717 - val_calculate_relative_error: 543538.7500 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 239s 13s/step - loss: 0.0318 - mae: 0.1023 - mean_absolute_percentage_error: 3037.0376 - calculate_relative_error: 739335.1250 - val_loss: 0.0263 - val_mae: 0.0961 - val_mean_absolute_percentage_error: 2329.2556 - val_calculate_relative_error: 540746.6875 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 279s 15s/step - loss: 0.0318 - mae: 0.1048 - mean_absolute_percentage_error: 3020.3020 - calculate_relative_error: 733975.3750 - val_loss: 0.0262 - val_mae: 0.0973 - val_mean_absolute_percentage_error: 2320.2598 - val_calculate_relative_error: 538200.6250 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 260s 14s/step - loss: 0.0315 - mae: 0.1050 - mean_absolute_percentage_error: 3009.7524 - calculate_relative_error: 732720.6250 - val_loss: 0.0260 - val_mae: 0.0958 - val_mean_absolute_percentage_error: 2331.6565 - val_calculate_relative_error: 541659.5000 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 291s 16s/step - loss: 0.0313 - mae: 0.1033 - mean_absolute_percentage_error: 3027.2122 - calculate_relative_error: 737140.0000 - val_loss: 0.0258 - val_mae: 0.0954 - val_mean_absolute_percentage_error: 2335.2502 - val_calculate_relative_error: 542520.7500 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 292s 16s/step - loss: 0.0312 - mae: 0.1037 - mean_absolute_percentage_error: 3021.8315 - calculate_relative_error: 735797.5625 - val_loss: 0.0257 - val_mae: 0.0958 - val_mean_absolute_percentage_error: 2331.5393 - val_calculate_relative_error: 541413.6875 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 263s 14s/step - loss: 0.0311 - mae: 0.1037 - mean_absolute_percentage_error: 3021.9971 - calculate_relative_error: 735792.1875 - val_loss: 0.0256 - val_mae: 0.0957 - val_mean_absolute_percentage_error: 2332.0474 - val_calculate_relative_error: 541787.0625 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 247s 13s/step - loss: 0.0310 - mae: 0.1036 - mean_absolute_percentage_error: 3022.0796 - calculate_relative_error: 735814.1875 - val_loss: 0.0255 - val_mae: 0.0957 - val_mean_absolute_percentage_error: 2332.7732 - val_calculate_relative_error: 541961.7500 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "11/19 [================>.............] - ETA: 1:33 - loss: 0.0317 - mae: 0.1044 - mean_absolute_percentage_error: 3152.9509 - calculate_relative_error: 782240.4375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 189\u001b[0m\n\u001b[1;32m    186\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Load the best model saved during training\u001b[39;00m\n\u001b[1;32m    195\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, RandomFlip, RandomRotation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError  # Import the MAPE metric\n",
    "\n",
    "\n",
    "csv_folder_path = '/Users/shubhibhadauriya/Desktop/Diss Project/osfstorage-archive (1)'  \n",
    "image_base_path = '/Users/shubhibhadauriya/Desktop/osfstorage-archive'\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(csv_folder_path) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "all_filenames = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "def find_image_file(csv_filename, image_dir):\n",
    "    parts = csv_filename.split('/')\n",
    "    timestamp_id = parts[-1].split('-')[0]\n",
    "    corrected_timestamp_id = timestamp_id.replace(':', '/')\n",
    "    for root, dirs, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            if corrected_timestamp_id in file:\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_images(filenames, base_path):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        img_path = find_image_file(filename, base_path)\n",
    "        if img_path and os.path.exists(img_path):\n",
    "            images.append(img_path)\n",
    "        else:\n",
    "            print(f\"File not found for CSV entry: {filename}\")\n",
    "            images.append(None)  \n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    csv_file_path = os.path.join(csv_folder_path, csv_file)\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    data = data.dropna()\n",
    "\n",
    "    \n",
    "    image_width, image_height = 960, 960  \n",
    "    data['lx'] = data['lx'] / image_width\n",
    "    data['ly'] = data['ly'] / image_height\n",
    "    data['rx'] = data['rx'] / image_width\n",
    "    data['ry'] = data['ry'] / image_height\n",
    "\n",
    "    features = ['lx', 'ly', 'rx', 'ry']\n",
    "\n",
    "    \n",
    "    filenames = data['filename'].values\n",
    "    images = load_images(filenames, image_base_path)\n",
    "    labels = data[features].values\n",
    "\n",
    "    \n",
    "    valid_indices = [i for i, img in enumerate(images) if img is not None]\n",
    "    images = images[valid_indices]\n",
    "    labels = labels[valid_indices]\n",
    "\n",
    "    \n",
    "    all_filenames.extend(images)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "\n",
    "all_filenames = tf.convert_to_tensor(all_filenames, dtype=tf.string)\n",
    "all_labels = tf.convert_to_tensor(all_labels, dtype=tf.float32)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_filenames, all_labels))\n",
    "\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=len(all_filenames), seed=38)\n",
    "\n",
    "\n",
    "sampled_dataset = dataset.take(1000)\n",
    "\n",
    "\n",
    "train_size = int(0.6 * 1000)\n",
    "val_size = int(0.2 * 1000)\n",
    "test_size = 1000 - train_size - val_size\n",
    "\n",
    "train_dataset = sampled_dataset.take(train_size)\n",
    "val_test_dataset = sampled_dataset.skip(train_size)\n",
    "val_dataset = val_test_dataset.take(val_size)\n",
    "test_dataset = val_test_dataset.skip(val_size)\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(filename, label):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [299, 299])  \n",
    "    image = image / 255.0  \n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "augmentation_layers = [\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.cache().batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(299, 299, 3))  \n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.6)(x)  \n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)  \n",
    "x = Dropout(0.6)(x) \n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "predictions = Dense(4, activation='linear')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "def euclidean_distance(true_coords, pred_coords):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(true_coords - pred_coords), axis=-1))\n",
    "\n",
    "\n",
    "epsilon = 1e-7  \n",
    "\n",
    "def calculate_relative_error(y_true, y_pred):\n",
    "    true_lx, true_ly, true_rx, true_ry = tf.split(y_true, 4, axis=-1)\n",
    "    pred_lx, pred_ly, pred_rx, pred_ry = tf.split(y_pred, 4, axis=-1)\n",
    "\n",
    "    d_left_eye = euclidean_distance(tf.concat([true_lx, true_ly], axis=-1), \n",
    "                                    tf.concat([pred_lx, pred_ly], axis=-1))\n",
    "    d_right_eye = euclidean_distance(tf.concat([true_rx, true_ry], axis=-1), \n",
    "                                     tf.concat([pred_rx, pred_ry], axis=-1))\n",
    "\n",
    "    \n",
    "    w = euclidean_distance(tf.concat([true_lx, true_ly], axis=-1), \n",
    "                           tf.concat([true_rx, true_ry], axis=-1)) + epsilon\n",
    "\n",
    "    relative_error_left = d_left_eye / w\n",
    "    relative_error_right = d_right_eye / w\n",
    "    relative_error = tf.maximum(relative_error_left, relative_error_right)\n",
    "    \n",
    "    return relative_error\n",
    "\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)  \n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=['mae', MeanAbsolutePercentageError(name=\"mean_absolute_percentage_error\"), calculate_relative_error])\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)  \n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=100,  \n",
    "                    callbacks=[reduce_lr, checkpoint])\n",
    "\n",
    "\n",
    "model.load_weights('best_model.keras')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title(f'{model_name} Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['mae'], label='train_mae')\n",
    "    plt.plot(history.history['val_mae'], label='val_mae')\n",
    "    plt.title(f'{model_name} MAE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['mean_absolute_percentage_error'], label='train_mape')\n",
    "    plt.plot(history.history['val_mean_absolute_percentage_error'], label='val_mape')\n",
    "    plt.title(f'{model_name} MAPE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['calculate_relative_error'], label='train_relative_error')\n",
    "    plt.plot(history.history['val_calculate_relative_error'], label='val_relative_error')\n",
    "    plt.title(f'{model_name} Relative Error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9327c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test data\n",
    "#test_loss, test_mae, test_mape, test_relative_error = model.evaluate(test_dataset)\n",
    "#print(f\"Test Loss: {test_loss}\")\n",
    "#print(f\"Test MAE: {test_mae}\")\n",
    "#print(f\"Test MAPE: {test_mape}\")\n",
    "#print(f\"Test Relative Error: {test_relative_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-5)  \n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=['mae', MeanAbsolutePercentageError(name=\"mean_absolute_percentage_error\"), calculate_relative_error])\n",
    "\n",
    "\n",
    "checkpoint_finetune = ModelCheckpoint('best_finetuned_model.keras', \n",
    "                                      monitor='val_loss', \n",
    "                                      save_best_only=True, \n",
    "                                      mode='min',\n",
    "                                      verbose=1)\n",
    "\n",
    "\n",
    "epochs = 50  \n",
    "print(\"Fine-tuning the entire model\")\n",
    "history_finetune = model.fit(train_dataset,\n",
    "                             validation_data=val_dataset,\n",
    "                             epochs=epochs,\n",
    "                             callbacks=[reduce_lr, checkpoint_finetune])\n",
    "\n",
    "\n",
    "plot_history(history_finetune, 'InceptionResNetV2 Fine-Tuned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd432a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test data\n",
    "#test_loss, test_mae, test_mape, test_relative_error = model.evaluate(test_dataset)\n",
    "#print(f\"Test Loss: {test_loss}\")\n",
    "#print(f\"Test MAE: {test_mae}\")\n",
    "#print(f\"Test MAPE: {test_mape}\")\n",
    "#print(f\"Test Relative Error: {test_relative_error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
